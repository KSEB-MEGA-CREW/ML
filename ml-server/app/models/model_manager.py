# model_manager.py
import tensorflow as tf
import os
import logging
import json
import asyncio
from pathlib import Path
import numpy as np
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

# TensorFlow ì„¤ì •
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
tf.config.experimental.enable_op_determinism()


class ModelManager:
    def __init__(self):
        self.model = None
        self.labels = None
        self.is_loaded = False
        self.executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="model")
        self._load_lock = asyncio.Lock()

    async def load_model(self) -> bool:
        """ëª¨ë¸ ë¡œë”© - ì¤‘ë³µ ë¡œë”© ë°©ì§€"""
        if self.is_loaded:
            return True

        async with self._load_lock:
            if self.is_loaded:  # ë‹¤ì‹œ í™•ì¸
                return True

            try:
                logger.info("ğŸš€ ëª¨ë¸ ë¡œë”© ì‹œì‘...")

                # ë¼ë²¨ íŒŒì¼ ê²½ë¡œ
                label_paths = [
                    Path("models/label_map.json"),
                    Path("../models/label_map.json"),
                    Path("/app/models/label_map.json"),
                ]

                # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
                model_paths = [
                    Path("models/gesture_model.h5"),
                    Path("../models/gesture_model.h5"),
                    Path("/app/models/gesture_model.h5"),
                ]

                # ë¼ë²¨ ë¡œë”©
                labels_path = next((p for p in label_paths if p.exists()), None)
                if not labels_path:
                    logger.error("âŒ ë¼ë²¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    return False

                with open(labels_path, "r", encoding="utf-8") as f:
                    label_list = json.load(f)
                self.labels = {str(i): label for i, label in enumerate(label_list)}
                logger.info(f"ğŸ“‹ ë¼ë²¨ ë¡œë”© ì™„ë£Œ: {len(self.labels)}ê°œ")

                # ëª¨ë¸ ë¡œë”©
                model_path = next((p for p in model_paths if p.exists()), None)
                if not model_path:
                    logger.error("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    return False

                logger.info(f"ğŸ“¦ ëª¨ë¸ ë¡œë”©: {model_path}")
                self.model = tf.keras.models.load_model(model_path, compile=False)

                # ì›Œë°ì—…
                dummy_input = np.random.random((1, 10, 194)).astype(np.float32)
                _ = self.model.predict(dummy_input, verbose=0)

                self.is_loaded = True
                logger.info("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
                return True

            except Exception as e:
                logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                return False

    def is_model_ready(self) -> bool:
        """ëª¨ë¸ ì¤€ë¹„ ìƒíƒœ í™•ì¸"""
        return self.is_loaded and self.model is not None

    def _predict_sync(self, keypoints_sequence: List[List[float]]) -> Dict:
        """ë™ê¸° ì˜ˆì¸¡ í•¨ìˆ˜ - ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë¨"""
        if not self.is_loaded or self.model is None:
            raise RuntimeError("Model not loaded")

        try:
            # ì…ë ¥ ë°ì´í„° ë³€í™˜ ë° ê²€ì¦
            features = np.array(keypoints_sequence, dtype=np.float32)

            # í˜•íƒœ ê²€ì¦
            if features.shape != (10, 194):
                raise ValueError(
                    f"Invalid input shape: {features.shape}, expected (10, 194)"
                )

            # ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜: (1, 10, 194)
            features = features.reshape(1, 10, 194)

            # ì˜ˆì¸¡ ìˆ˜í–‰
            probability_vector = self.model.predict(features, verbose=0)
            predicted_class_index = np.argmax(probability_vector[0])
            confidence = float(probability_vector[0][predicted_class_index])
            label = self.labels.get(str(predicted_class_index), "Unknown")

            logger.debug(f"ì˜ˆì¸¡ ì™„ë£Œ: {label} (ì‹ ë¢°ë„: {confidence:.3f})")

            return {
                "label": label,
                "confidence": confidence,
                "class_id": int(predicted_class_index),
            }

        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    async def predict_async(
        self, keypoints_sequence: List[List[float]]
    ) -> Optional[Dict]:
        """ë¹„ë™ê¸° ì˜ˆì¸¡ - ê°•í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬"""
        if not self.is_loaded:
            logger.error("ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•ŠìŒ")
            return None

        try:
            # ì…ë ¥ ë°ì´í„° ì‚¬ì „ ê²€ì¦
            if not keypoints_sequence:
                logger.error("ë¹ˆ í‚¤í¬ì¸íŠ¸ ì‹œí€€ìŠ¤")
                return None

            if len(keypoints_sequence) != 10:
                logger.error(f"ì˜ëª»ëœ ì‹œí€€ìŠ¤ ê¸¸ì´: {len(keypoints_sequence)}, ì˜ˆìƒ: 10")
                return None

            # ìŠ¤ë ˆë“œ í’€ì—ì„œ ì˜ˆì¸¡ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self.executor, self._predict_sync, keypoints_sequence
            )

            return result

        except Exception as e:
            logger.error(f"ë¹„ë™ê¸° ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            logger.exception("ì˜ˆì¸¡ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´:")
            return None


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
model_manager = ModelManager()
