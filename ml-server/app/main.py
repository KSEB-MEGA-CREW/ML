import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from app.models.model_loader import ModelManager
from dotenv import load_dotenv
import logging

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Mega-Crew SLT AI Server",
    description="ì‹¤ì‹œê°„ ìˆ˜í™” ë²ˆì—­ AI ì„œë²„",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
)
# model loader/cache
model_manager = ModelManager()

# CORS ì„¤ì • (FE,BE ì—°ê²°ìš©)
# BE ->(frame data) -> AI
# AI ->(gloss data) -> FE
# AI ->(interpreted text) -> FE
# front : http://mega-crew-react-deploy.s3-website.ap-northeast-2.amazonaws.com
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:8080",
        "http://localhost:3000",
        "http://mega-crew-react-deploy.s3-website.ap-northeast-2.amazonaws.com",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ì •ì˜
# class HealthResponse(BaseModel):
#     status: str
#     message: str
#     version: str


# class FrameRequest(BaseModel):
#     frame_data: str  # Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
#     timestamp: int
#     session_id: str
#     frame_index: int


# class FrameResponse(BaseModel):
#     success: bool
#     result: dict = None  # text -> aws bedrockì— ì—°ê²°


# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": "Sign Language AI Server", "status": "running", "docs": "/docs"}


# @app.get("/health", response_model=HealthResponse)
# async def health_check():
#     """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
#     return HealthResponse(
#         status="healthy", message="AI ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤.", version="1.0.0"
#     )


# ì„ì‹œ í”„ë ˆì„ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ (ëª¨ë¸ ë¡œë“œ ì „)
# @app.post("/analyze-frame", response_model=FrameResponse)
# async def analyze_frame(request: FrameRequest):
#     """í”„ë ˆì„ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ (ì„ì‹œ êµ¬í˜„)"""
#     try:
#         logger.info(
#             f"í”„ë ˆì„ ë¶„ì„ ìš”ì²­ - Session: {request.session_id}, Frame: {request.frame_index}"
#         )

#         # ì„ì‹œ ì‘ë‹µ (ì‹¤ì œ ëª¨ë¸ êµ¬í˜„ ì „)
#         return FrameResponse(
#             success=True,
#             message="í”„ë ˆì„ ë¶„ì„ ì™„ë£Œ (ì„ì‹œ)",
#             result={
#                 "predicted_text": "ì•ˆë…•í•˜ì„¸ìš”",
#                 "confidence": 0.85,
#                 "processing_time": 0.1,
#             },
#         )

#     except Exception as e:
#         logger.error(f"í”„ë ˆì„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
#         raise HTTPException(
#             status_code=500, detail=f"í”„ë ˆì„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
#         )


# ì„œë²„ ì •ë³´ ì—”ë“œí¬ì¸íŠ¸
@app.get("/info")
async def server_info():
    """ì„œë²„ ì •ë³´ ì¡°íšŒ"""
    return {
        "server": "Sign Language AI Server",
        "version": "1.0.0",
        "python_version": "3.9+",
        "framework": "FastAPI",
        "endpoints": {
            "health": "/health",
            "analyze": "/analyze-frame",
            "docs": "/docs",
        },
    }


# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸
@app.on_event("startup")
async def startup_event():
    logger.info("AI ì„œë²„ ì‹œì‘ ì¤‘...")
    success = await model_manager.load_model()
    if not success:
        logger.error("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - ì„œë²„ ì‹œì‘ ì¤‘ë‹¨")
        raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
    logger.info("AI ì„œë²„ ì‹œì‘ ì™„ë£Œ")


@app.get("/health")
async def health_check():
    return {"status": "healthy", "model_loaded": model_manager.is_ready()}


@app.get("/model/status")
async def model_status():
    return {
        "loaded": model_manager.is_ready(),
        "cache_info": (
            "cached"
            if model_manager.cache.is_cached(
                model_manager.s3_client.settings.MODEL_S3_KEY
            )
            else "not_cached"
        ),
    }


@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    logger.info("ğŸ›‘ AI ì„œë²„ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    import uvicorn

    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", "8000"))
    debug = os.getenv("DEBUG", "True").lower() == "true"

    uvicorn.run("main:app", host=host, port=port, reload=debug, log_level="info")
